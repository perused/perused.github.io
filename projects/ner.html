<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1" />
    <title>NER Project</title>
    <link rel="shortcut icon" href="../img/favicon.ico">
    <link rel="stylesheet" href="../css/main.css">
    <link rel="stylesheet" href="../css/bootstrap.min.css">
  </head>
  <body class="project">

    <div class="flex" id="home">
      <a class="home" href="../index.html" title="Go Home"><img class="home-img" src="../img/home.png"></a>
    </div>

    <h1>Named Entity Recognition</h1>

    <p class="pd">PyTorch bidirectional LSTM with CRF attachment and encoder-decoder attention for the Named Entity Recognition task. <a class="project-hyperlink" href="https://en.wikipedia.org/wiki/Named-entity_recognition" target="_blank">What is Named Entity Recognition?</a></p>

    <img class="jeff" src="../img/gifs/ner.gif">

    <!-- <p class="pd">The following page describes the process of creating a named entity recognition (NER) model. The use of input embeddings and the architecture of the model are described in detail, with justifications of decisions made throughout the development process.</p>  -->

    <h3>The Data</h3>

    <p class="pd">The data was a curated selection from the <a href="https://github.com/dstl/re3d" target="_blank">re3d dataset</a>, which is a dataset obtained that has been obtained from defense related communications.</p>

    <h3>Input Embeddings</h3>

    <p class="pd">In this task, three input embeddings were used: syntactic, semantic and domain feature embeddings. Syntactic embeddings were the POS tags of a token and dependency paths for the token, its parent and its children. Semantic feature embeddings were Glove word embeddings with a dimension of 300. Domain embeddings were a 13 dimension gazetteer constructed using data from <a href="https://github.com/hltcoe/gazetteer-collection" target="_blank">here</a>. Each dimension of the gazetteer embedding was targeted at things likely to appear in the data, such as time units and locations.</p>

    <h3>NER Model</h3>

    <p class="pd">The final model decided on for the task was a bidirectional LSTM with a CRF attachment and encoder-decoder general attention. Various models were experimented on, such as with and without attention, with and without the CRF attachement as well as multi-headed self-attention in various locations as well, but the final model was the best performing.</p>

    <p class="pd">The model used negative log likelihood loss and the Adam optimiser during training. The Viterbi algorithm was used for CRF decoding.</p>

    <h4>Encoder-Decoder Attention</h4>

    <p class="pd">Encoder-decoder attention involved calculating the attention scores directly before the output layer. The current hidden state of the decoder had attention computed between it and each hidden state of the encoder for the current input only (thus it was local, not global, attention). Interestingly, it was found that general attention outperformed dot product and scaled dot product attention. These attention scores were then passed thorugh a softmax function and this output was concatenated with the current decoder hidden state. This concatenated output was then fed through a linear layer where it could be fed to a CRF for decoding.</p>

    <h4>CRF</h4>

    <p class="pd">The CRF component would take the output of the bi-LSTM and using the Viterbi algorithm, decode the most likely predictions for the model output. One obvious benefit of using a CRF for the NER task is that 'beginning' tags never precede an 'inside' tag, which is an issue that can be seen when CRF is not used.</p>

  </body>
</html>